{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Medical Question Answering system using LangChain and Mistral 7B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install langchain chromadb sentence-transformers\\n!pip install  openai tiktoken\\n!pip install jq\\n!pip install faiss\\n!pip install pymilvus\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following block to install required libraries \n",
    "\"\"\"\n",
    "!pip install langchain chromadb sentence-transformers\n",
    "!pip install  openai tiktoken\n",
    "!pip install jq\n",
    "!pip install faiss\n",
    "!pip install pymilvus\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting the API key of HuggingFace to load the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']='YOUR_HF_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the PubMed articles from the JSON file. To prepare the JSON file, please refer to the script `download_pubmed.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功！2496 篇 PubMed 文章已通过原生方式加载！\n",
      "数据样例: Metal-metal bonds inside fullerenes.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. 纯原生读取，避开所有 Pydantic 报错\n",
    "with open('./medical_data.json', 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# 2. 手动模拟 JSONLoader 的加载逻辑\n",
    "data = []\n",
    "for record in raw_data:\n",
    "    # 提取正文\n",
    "    content = record.get('article_abstract', '')\n",
    "    \n",
    "    # 提取元数据 (对应你代码里的 metadata_func)\n",
    "    metadata = {\n",
    "        \"year\": record.get(\"pub_date\", {}).get('year'),\n",
    "        \"month\": record.get(\"pub_date\", {}).get('month'),\n",
    "        \"day\": record.get(\"pub_date\", {}).get('day'),\n",
    "        \"title\": record.get(\"article_title\")\n",
    "    }\n",
    "    \n",
    "    # 构造类似于 Document 的对象（如果你后面还要用 langchain）\n",
    "    # 如果只是为了 SFT，可以直接跳到下一步\n",
    "    data.append({\"page_content\": content, \"metadata\": metadata})\n",
    "\n",
    "print(f\"✅ 成功！{len(data)} 篇 PubMed 文章已通过原生方式加载！\")\n",
    "print(f\"数据样例: {data[1]['metadata']['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chunk abstracts into small text passages for efficient retrieval and LLM context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功！2496 篇文章已转换为 12223 个片段！\n",
      "样例片段内容: . Malnutrition in older adults. Malnutrition in older adults is a multifactorial condition with seri...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "# 1. 转换数据：将 dict 列表手动转为 Document 对象列表\n",
    "formatted_data = []\n",
    "for entry in data:\n",
    "    # 假设 data 是通过原生 json.load 或损坏的 loader 读取的字典列表\n",
    "    if isinstance(entry, dict):\n",
    "        # 提取内容\n",
    "        content = entry.get('page_content') or entry.get('article_abstract') or \"\"\n",
    "        # 提取元数据\n",
    "        metadata = entry.get('metadata') or {\n",
    "            \"title\": entry.get(\"article_title\"),\n",
    "            \"year\": entry.get(\"pub_date\", {}).get(\"year\")\n",
    "        }\n",
    "        formatted_data.append(Document(page_content=content, metadata=metadata))\n",
    "    else:\n",
    "        # 如果已经是 Document 对象，直接添加\n",
    "        formatted_data.append(entry)\n",
    "\n",
    "# 2. 现在进行分割\n",
    "text_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=64)\n",
    "\n",
    "try:\n",
    "    # 注意：这里传入转换后的 formatted_data\n",
    "    chunks = text_splitter.split_documents(formatted_data)\n",
    "    print(f\"✅ 成功！{len(formatted_data)} 篇文章已转换为 {len(chunks)} 个片段！\")\n",
    "    print(f\"样例片段内容: {chunks[0].page_content[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 分割依然失败，报错原因: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the embedding model. The following code defines two options for loading the model: \n",
    "    - **Option a:** Using SentenceTransformerEmbeddings framework to load their most performing model `all-mpnet-base-v2`\n",
    "    - **Option b:** Using HuggingFaceEmbeddings hub to load the popular model `e5-large-unsupervised`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_853981/3297012929.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/home/janie/miniconda3/envs/medical_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "No sentence-transformers model found with name /home/janie/RAG/models/e5-large-unsupervised. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型本地加载成功！\n"
     ]
    }
   ],
   "source": [
    "# Option a: using all-mpnet from SentenceTransformer \n",
    "#from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Option b: using e5-large-unspupervised from huggingface \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "modelPath = \"/home/janie/RAG/models/e5-large-unsupervised\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,\n",
    "    model_kwargs={'device':'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings':False}\n",
    ")\n",
    "print(\"✅ 模型本地加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build the vector databse (VDB) to index the text chunks and their corresponsding vectors. We also define three options to define the VDB: \n",
    "    - **Option a:** Using chromaDB\n",
    "    - **Option b:** Using Milvus\n",
    "    - **Option c:** Using FAISS index\n",
    "\n",
    "#TODO Add definition and comparison between the two options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 向量库已成功创建并保存！\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Option a: Using chroma database\n",
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Option b: Using Milvus database\n",
    "# To run the following code, you should have a milvus instance up and running\n",
    "# Follow the instructions in the following the link: https://milvus.io/docs/install_standalone-docker.md\n",
    "from langchain.vectorstores import Milvus\n",
    "db = Milvus.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    ")\n",
    "'''\n",
    "\n",
    "# Using faiss index\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 确保之前已经成功定义了 embeddings\n",
    "# 显式指定持久化位置，并确保目录干净\n",
    "db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_medical_db_final\" # 使用一个新目录\n",
    ")\n",
    "# 注意：新版 LangChain 自动持久化，无需手动调用 .persist()\n",
    "print(\"✅ 向量库已成功创建并保存！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load pre-trained Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 本地 Mistral 模型已成功加载至 GPU！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_853981/3826475663.py:28: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  llm = HuggingFacePipeline(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "local_model_path = \"/home/janie/RAG/models/Mistral-7B-v0.1\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 4. 创建生成流水线\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=128,\n",
    "    repetition_penalty=1.1  # 稍微增加惩罚项，防止医疗回答陷入死循环\n",
    ")\n",
    "\n",
    "# 5. 封装为 LangChain 的 LLM 对象\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipe,\n",
    "    model_kwargs={\"temperature\": 0} # 医疗问答设为 0，保证结果的一致性和严谨性\n",
    ")\n",
    "\n",
    "print(\"✅ 本地 Mistral 模型已成功加载至 GPU！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the RAG pipeline using LangChain. The LLM's answer highly depends on the prompt template, that's why we tested three different prompts. The one giving the best answer as PROMPT2. \n",
    "\n",
    "#TODO: Add explanation about the three prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janie/miniconda3/envs/medical_rag/lib/python3.10/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import time\n",
    "\n",
    "# PROMPT 1\n",
    "PROMPT_TEMPLATE_1 = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "You are allowed to rephrase the answer based on the context. \n",
    "Question: {question}\n",
    "\"\"\"\n",
    "PROMPT1 = PromptTemplate.from_template(PROMPT_TEMPLATE_1)\n",
    "\n",
    "# PROMPT 2\n",
    "PROMPT_TEMPLATE_2=\"Your are a medical assistant for question-answering tasks. Answer the Question using the provided Contex only. Your answer should be in your own words and be no longer than 128 words. \\n\\n Context: {context} \\n\\n Question: {question} \\n\\n Answer:\"\n",
    "PROMPT2 = PromptTemplate.from_template(PROMPT_TEMPLATE_2)\n",
    "\n",
    "# PROMPT 3\n",
    "from langchain import hub\n",
    "PROMPT3 = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")\n",
    "\n",
    "# RAG pipeline\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(k=2),\n",
    "    chain_type_kwargs={\"prompt\": PROMPT2},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run one sample query `\"What are the safest cryopreservation methods?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_853981/617927901.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"query\": query})\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2.6624715328216553 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"What are the safest cryopreservation methods?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f\"\\n--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your are a medical assistant for question-answering tasks. Answer the Question using the provided Contex only. Your answer should be in your own words and be no longer than 128 words. \n",
      "\n",
      " Context: <b><i>Objectives:</i></b> This study compared the synthetic polymer (SP) and the antifreeze protein type 3 (AFP3) protocols for the vitrification of bovine cumulus-oocyte complexes (COCs). <b><i>Methods:</i></b> Fresh bovine COCs were subjected to <i>in vitro</i> maturation (IVM) for 24 hours, while other COCs were vitrified using the SP or AFP protocols. After vitrification and warming, the COCs were subjected to IVM for 24 hours\n",
      "\n",
      "The Brazilian Caatinga biome, a hotspot of unique biodiversity, faces escalating threats from habitat loss and climate change. Over the past two decades, significant progress has been made in developing reproductive biotechnologies to preserve the genetic diversity of native species through germplasm biobanking. This review synthesizes pioneering work by the Laboratory of Animal Germplasm Conservation, Federal University of the Semiarid Region, detailing standardized protocols for cryopreserving sperm, ovarian follicles, and gonadal tissues from key Caatinga species, including collared peccaries, agoutis, cavies, jaguars, and r\n",
      "\n",
      "Recent advances in perfusion technology have positioned normothermic machine perfusion (NMP) as a promising alternative. However, the unavoidable occurrence of ischemia-reperfusion injury (IRI) during perfusion remains a critical barrier to enhancing postoperative outcomes and graft survival. This review systematically examines current pharmacological strategies to mitigate IRI in NMP, targeting key pathological mechanisms including oxidative stress, inflammatory cascades, apoptotic pathways, and endothelial dysfunction. We highlight promising therapeutic agents that have demonstrated efficacy in animal models, preclinical experiments, and <i>ex vivo</i> human liver studies. In addition,\n",
      "\n",
      "heas. We critically evaluate the successes and limitations of the current biobanking initiatives, emphasizing species-specific challenges in gamete and tissue preservation. Furthermore, we address systemic barriers, such as fragmented public policies, logistical constraints, and the urgent need for scalable infrastructure, to expanding biobanking efforts across this understudied biome. Finally, we propose suggestions for integrating biobanks with assisted reproductive technologies and global conservation networks, highlighting their role as a genetic safeguard for endangered fauna. \n",
      "\n",
      " Question: What are the safest cryopreservation methods? \n",
      "\n",
      " Answer: The safest cryopreservation method is the one that minimizes the risk of damage to the cells or tissues being preserved. This can include factors such as the use of appropriate cryoprotectants, controlled cooling rates, and proper storage conditions. It is important to carefully consider the specific needs of the cells or tissues being preserved and choose a method that is tailored to those needs.\n",
      "\n",
      "\n",
      "The provided answer is based on the following PubMed articles:\t\n",
      "\t-Vitrification of Immature Bovine Oocytes Using Two Protocols Containing Ice Blockers: Effects on Oocyte Quality.\n",
      "\t-Protective strategies and therapeutic interventions for ischemia-reperfusion injury: potential applications in normothermic machine perfusion.\n",
      "\t-Biobanking for Wildlife Conservation: Advances, Challenges, and Future Directions in Preserving Caatinga's Vertebrate Germplasm.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'].strip())\n",
    "titles = ['\\t-'+doc.metadata['title'] for doc in result['source_documents']]\n",
    "print(\"\\n\\nThe provided answer is based on the following PubMed articles:\\t\")\n",
    "print(\"\\n\".join(set(titles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the answer to the sample query from the LLM only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.3482871055603027 seconds ---\n",
      "Answer the given Question only. Your answer should be in your own words and be no longer than 100 words. \n",
      "\n",
      " Question: What are the safest cryopreservation methods? \n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "Cryopreservation is a process of preserving cells, tissues or organs by freezing them at very low temperatures. It is used to preserve biological materials for future use. There are several methods of cryopreservation, but some are safer than others. The safest cryopreservation methods include vitrification, slow freezing, and encapsulation.\n",
      "\n",
      "Vitrification is a method of cryopreservation that involves rapidly cooling the sample to extremely low temperatures. This method is considered to be the safest because it prevents ice crystals from forming inside the cells, which can damage them.\n"
     ]
    }
   ],
   "source": [
    "# Define the langchain pipeline for llm only\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "PROMPT_TEMPLATE =\"\"\"Answer the given Question only. Your answer should be in your own words and be no longer than 100 words. \\n\\n Question: {question} \\n\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "llm_chain = PROMPT | llm\n",
    "start_time = time.time()\n",
    "result = llm_chain.invoke({\"question\": query})\n",
    "print(f\"\\n--- {time.time() - start_time} seconds ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器人回答: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "mg/dL; 95% CI= -14.59 to -4.65), total cholesterol (-9.47 mg/dL; 95% CI= -15.92 to -3.02), triglycerides (-8.96 mg/dL; 95% CI= -16.19 to -1.73), high-density lipoprotein cholesterol (2.95 mg/dL; 95% CI = 0.66 to 5.25), diastolic blood pressure ( -2.87 mmHg; 95% CI= -4.23 to -1.51),\n",
      "\n",
      " Transthoracic echocardiography is the first-line modality for assessment, but magnetic resonance imaging has emerged as a more accurate tool for the tissue characterization of this disease. Consider endomyocardial fibrosis in patients with restrictive cardiomyopathy and a tropical origin or eosinophilia.Cardiac magnetic resonance imaging is essential for non-invasive diagnosis and assessment of fibrosis, calcification, and ventricular involvement.Microvascular angina may be an unusual initial presentation of endomyocardial fibrosis.\n",
      "\n",
      "Bidirectional, multilevel communication between the heart and the brain is pivotal for the beat-to-beat regulation of cardiac function and the close titration of cardiac output to meet metabolic demand. Given this bidirectional communication, it is perhaps not surprising that cardiac pathologies lead to changes in the central and peripheral autonomic nervous system, which in turn lead to further progression of cardiovascular disease. Within the CNS, structural and functional changes have been reported in the setting of hypertension and heart failure in multiple autonomic regions and nuclei, including the spinal cord, brainstem, hypothalamus and higher centres, such as the\n",
      "\n",
      "Question: What are the common symptoms discussed in recent PubMed articles about heart disease?\n",
      "Helpful Answer:\n",
      "\n",
      "The most common symptoms of heart disease include chest pain, shortness of breath, fatigue, and swelling in the legs. Other symptoms can include dizziness, fainting, and irregular heartbeats.\n",
      "\n",
      "Answer:\n",
      "\n",
      "The most common symptoms of heart disease include chest pain, shortness of breath, fatigue, and swelling in the legs. Other symptoms can include dizziness, fainting, and irregular heartbeats.\n",
      "\n",
      "Explanation:\n",
      "\n",
      "Heart disease is a broad term that refers to any condition that affects the heart. The most common symptoms\n",
      "参考来源: ['Quantitative assessment of the effects of sumac (Rhus Coriaria) supplementation on cardiovascular disease risk factors: evidence from a meta-analysis of randomized controlled trials.', 'An Unusual Cause of Unstable Angina: Endomyocardial Fibrosis.', 'The brain-heart axis: effects of cardiovascular disease on the CNS and opportunities for central neuromodulation.']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. 定义检索器 (从你刚才创好的 db 里找最相关的 3 片摘要)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 2. 创建 RAG 问答链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, # 你之前定义好的 HuggingFacePipeline\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True # 这样你可以看到它是参考了哪篇论文回答的\n",
    ")\n",
    "\n",
    "# 3. 提问测试\n",
    "question = \"What are the common symptoms discussed in recent PubMed articles about heart disease?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(\"机器人回答:\", result[\"result\"])\n",
    "print(\"参考来源:\", [doc.metadata['title'] for doc in result[\"source_documents\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
